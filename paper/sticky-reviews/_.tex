This work was submitted to
Eurocrypt 2023 and TCC 2023.
This section includes select review paragraphs
that either have been addressed (by revision)
or should be clarified (by reply).
They are grouped by \textbf{topic},
marked with \underlined{venue/review}
(e.g., \underlined{EC/A} for review A from Eurocrypt 2023),
\texttt{quoted} then discussed.
Not in every case did we revise the text.

\subsubsection{AH-PLBE/BTR Security Notion Relations.}
From \underlined{EC/A}:

\texttt{
On page 15, when defining the security notions for AH-PLBE, the \\
authors mentioned "The two security definitions have a one-to-one \\
correspondence to the simplified security notions of AH-BTR in Sect. \\
3.1". Intuitively, is it correct if I understand this detail as "an \\
AH-PLBE is a particular version of AH-BTR, with no tracing algorithm"? \\
If not, how can we interpret this "one-to-one correspondence"?
}

We have revised the text, currently around the middle of page~15, to clarify
which security property of AH-PLBE translates to (is used to prove)
which of AH-BTR in the classic scheme
(Construction~\ref{con:ahbtr-from-ahplbe}).
The best way to think about this is that
``AH-PLBE vs.~AH-BTR'' is similar to ``KEM vs.~PKE''.
In both cases, the former formally is not a particular version of the latter
--- aside from tracing,
AH-PLBE encryption takes a cut-off index as input but AH-BTR does not;
KEM encapsulation outputs a random message, i.e., the encapsulated key,
but PKE encryption takes the actual message as input ---
yet in both cases, the former is a ``dumbed down'' version of the latter
and the security properties of the former can be used to prove
those of the latter in classic constructions.

\subsubsection{Syntax of Restricted BE.}
From \underlined{EC/A}:

\texttt{
In Def. 18 of Section 7 for restricted BE, the decryption algorithm \\
receives only the security parameter in unary and is having random \\
accesses to the public key as well as the secret key. At the same \\
time, the correctness is required to be perfect. Out of curiosity, \\
is it plausible to require perfect correctness when giving only \\
random accesses to the secret key? Anyway, the lower bound proven \\
in Section 7 still holds even when relaxing the correctness.
}

For the purpose of this lower bound,
it is fine to assume that each secret key of restricted BE
contains a verbatim copy of the master public key.
We did not do this because our definition format
(explicitly giving components to algorithms
instead of letting any component ``absorb'' any other)
is customary when efficiency is a concern,
even if the particular efficiency property is unaffected
by the change of definition.

\subsubsection{Lemma from Auxiliary-Input Random Oracle Model.}
From \underlined{EC/A}:

\texttt{
In the statement of Lemma 10, is it a typo in the constraint \\
of the presampling function G that \\
\hspace*{4em}"\#\{G(z,j) {\string\neq} {\string\bot}\} <= P for all z {\string\in} Z"? \\
Shouldn't it be \\
\hspace*{4em}\ \#\{G(z,R)[j] {\string\neq} {\string\bot}\} <= P for all z {\string\in} Z \\
\hspace*{18.5em}w.r.t a fixed R? \\
Moreover, it is not clear to me why the oracle algorithm B can be \\
inefficient. Could the authors please elaborate more on this point?%
}

We have revised the statement of Lemma~\ref{lem:ai-rom},
currently around the bottom of page~27.
We have revised the text, in the footnotes of page~28, to clarify
that $\scriptB$ does not have to be efficient for the lemma to hold,
although in our application, we invoke the lemma for an efficient~$\scriptB$.

\subsubsection{Encryption Randomness in Proof.}
From \underlined{EC/A}:

\texttt{
In the proof of Theorem 9, why does z contain the encryption's \\
randomness? It seems that this enc's randomness is never used by B\string^Y \\
(to recover ct it parses f).
}

It is a formalism issue.
Lemma~\ref{lem:ai-rom} is for ``function~$F$'',
so $F$ cannot use randomness.
The encryption randomness is included for use by~$F$.

\subsubsection{Restricted BE Security Definition.}
From \underlined{EC/A}:

\texttt{
In the security notion of restricted BE, at the beginning of \\
page 22, i* and mu\_0 are still contained in the {\string\cdots} in the \\
distribution on the right hand side of the {\string\approx} property, aren't \\
they?
}

We have revised the text, currently around the top of page~27,
to make the definition clear.
(Answer to original question: Yes, they are still included.)

\subsubsection{Definition Style.}
From \underlined{EC/B}:

\texttt{
Why does Enc take 1\string^{\string\lambda} as an extra input, but not 1\string^N? \\
Giving 1\string^{\string\lambda} as an extra input seems okay, but could be avoided \\
too as done for most crypto objects.
}

The reviewer is talking about the definitions of AH-PLBE and AH-BTR.
We choose to not omit $\lambda$ as a style of consistency,
even when the other input is sufficiently long.
The list length is implicit in the list of public keys.

\subsubsection{Definition of AH-BTR Traceability.}
From \underlined{EC/B}:

\texttt{
What does S {\string\leftarrow} [Q] mean? Does it mean S := [Q]?
}

\texttt{
Also, why is B asked to declare Q at the beginning? A more \\
appropriate/general definition would be to let B make arbitrary \\
setup queries, and get handles to keys. Later it can decide which \\
to corrupt adaptively. Why these steps be sequential and not \\
interleaved?
}

We have revised the definition,
currently in the middle of page~13,
to be the natural (``appropriate/general'') version.
The confusion between
``sampling from a set'' (always done using $\draws$) and
``assigning a set to a variable'' (always done in words) is corrected.

\subsubsection{Random vs.\ Chosen Messages in AH-BTR.}
From \underlined{EC/B}:

\texttt{
Why doesn't B pick mu\_0 and mu\_1? There are picked randomly for \\
defining GoodDist. This deviates significantly from the formalization \\
standardized in TT literature.
}

We have revised the text, currently at the end of page~13,
following Definition~\ref{def:tracing-security},
to explain that KEM style definition is a customary simplification.

\subsubsection{Motivation.}
From \underlined{EC/C}:

\texttt{
I would like to have a clarification on the motivation of this \\
ad hoc traitor tracing notion.
}

We have revised the text, currently starting from the bottom of page~1,
to provide a more concrete description of the real-world motivation
(protesters' group chat scenario).
% Why do we study advanced cryptographic primitives
% that currently cannot be implemented to satisfactory practical efficiency
% at all?
% Because of intellectual curiosity, duh!

% \subsubsection{Further Applications of Techniques.}
% From \underlined{EC/C}:

% \texttt{
% What would be the further applications of the techniques \\
% proposed in this paper beyond traitor tracing?
% }

% There are quite a few techniques used in this paper.
 
% For example, we carefully combine laconic OT and obfuscation
% in a way that does not require non-falsifiable assumptions
% (the usual indistinguishability obfuscation is not falsifiable
% because we do not know how to check circuit equivalence in polynomial time;
% sub-exponential hardness is non-falsifiable
% because the advantage gap is
% too small to reject with high confidence in polynomial time).
% Further development of such techniques could help reduce
% reliance on non-falsifiable assumptions.
 
% Another example is the usage of auxiliary-input ROM simulation techniques.
% They have been extensively used to prove
% efficiency lower bounds for ``destructive'' tasks,
% namely, lower bounds of adversary advantage and size in AI-ROM.
% Here, we use it to prove efficiency lower bounds on a ``constructive'' task,
% as it is related to the efficiency parameters of a secure cryptographic scheme.
% Further exploration of these techniques for non-traditional usages
% is an interesting direction of research.

\subsubsection{Full Definition and Simplified Definitions.}
From \underlined{TCC/A}:

\texttt{
I wonder why do you need to give the full definition and then \\
the two equivalent smaller ones. I think it is not particularly \\
informative and I would have been as convinced with the two \\
equivalent definitions and it saves energy and effort from the \\
reader for the rest.
}

We have revise the text,
in the footnotes of page~5
and
around the top of page~14,
for clarification of security notion simplification.

As a paper studying a new notion,
the definition should arise from first principles.
Therefore, we first present the full definition.
Readers also have different familiarity
with possible simplifications of definitions,
cf.~EC/B ``why is B asked to declare Q at the beginning''
(in a previous version of the definition,
all the honestly generated public keys are created at the beginning,
instead of being instructed by the adversary).

In traditional traitor tracing,
similarly decomposing the definition into two
does not make the two properties much simpler ---
in particular, they will still be interactive.
This is due to the centralized nature of the set-up process ---
it is not possible to remove interaction of key creation and corruption.
The revised text now emphasizes this point.

\subsubsection{Notations Defined Too Late.}
From \underlined{TCC/A}:

\texttt{
In the intro, you use N before you say what it is.
}

We have revised the text,
currently in the middle of page~2,
to make it clear.

\subsubsection{Better Narration.}
From \underlined{TCC/A}:

\texttt{
A bit more intuition of why is Private Linear Broadcast Encryption \\
defined on this way would be useful, and some comment on why you don't \\
need mode indistinguishability also. The cut-off message appears in \\
the construction but not in the syntactic definition.
}

\texttt{
It would help me to get a more detailed explanation/intuition of \\
how Theorem 14 implies the lower bound.
}

We have revised the text,
currently in the middle of page~15,
to explain that mode indistinguishability is only for private traceability
(we consider public traceability in this work).

We have revised the text
to replace ``cut-off message'' by ``placeholder message''
for clarity.
The placeholder message is an implementation detail,
so it does not appear in the syntax.

For intuition on PLBE,
we believe the usage of PLBE for traitor tracing
is established in the literature.

For Theorem~\ref{thm:lower-bound},
the intuitive explanation is in the overview (search ``Back to AH-BTR'').

\subsubsection{Using Strong Tools.}
From \underlined{TCC/A}:

\texttt{
The weakest point is that the construction based on falsifiable \\
assumptions uses very strong tools (although they can all be based \\
on falsifiable assumptions).
}

The use of strong tools is simply because the construction in the manuscript
is the only successful attempt till now in achieving
all the desired properties ---
my intuition is that the most difficult part is doing it without global set-up.

\subsubsection{Applicability of Lower Bounds.}
From \underlined{TCC/A}:

\texttt{
The lower bound might not be very meaningful for small N.
}

We have revised the text, current in the lower half of page~27,
to explain why the phrasing ``for sufficiently large~$\lambda$'' is necessary
and when the bound ``starts to hold''.
We did not further optimize the constants in our bounds,
partly because a cell-probe argument
already fails to capture computation time outside memory access.
Nevertheless, we emphasize that the lower bound is the first of its kind
and asymptotically tightly characterizes all the possible efficiency frontiers.

\subsubsection{Absorption of $\poly(\log N)$ into $\poly(\lambda)$.}
From \underlined{TCC/A}:

\texttt{
I wonder to which extent it is fair to say that the AH-PLBE has \\
constant size ciphertexts ignoring the log N factor (the argument \\
is that since the ciphertext is poly({\string\lambda},log N) and \\
N {\string\leq} 2\string^\{{\string\lambda}\}, the ciphertext is poly({\string\lambda})).
}

We have revised the text,
currently in the footnotes of pages~6 and~18,
to explain why we should ignore $\poly(\lambda,\log N)$ factors
in asymptotic security.
